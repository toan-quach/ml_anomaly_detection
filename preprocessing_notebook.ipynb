{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d824fe1b-04e9-4701-8e55-c210b46ede42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73155634-f250-49fa-920f-d0abbc7315e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/preprocessed/Event_traces.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237f76f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16838.000000</td>\n",
       "      <td>575061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.375638</td>\n",
       "      <td>16789.470527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.344260</td>\n",
       "      <td>17886.993688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>33680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>54025.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type        Latency\n",
       "count  16838.000000  575061.000000\n",
       "mean       9.375638   16789.470527\n",
       "std       11.344260   17886.993688\n",
       "min        0.000000       0.000000\n",
       "25%        3.000000    1144.000000\n",
       "50%        5.000000    7229.000000\n",
       "75%        8.000000   33680.000000\n",
       "max       31.000000   54025.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4542de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 30% of 'Success' rows to reduce memory consumption\n",
    "success_idx = (\n",
    "    data.loc[data[\"Label\"] == \"Success\"]\n",
    "        .sample(frac=0.40, random_state=42)\n",
    "        .index\n",
    ")\n",
    "data = data.drop(success_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0ca56a-0705-4177-a17f-00e61779bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string sequence to list sequence\n",
    "data[\"Features\"] = data[\"Features\"].map(lambda x: x[1:-1].split(\",\"))\n",
    "\n",
    "# can map timeinterval with the operation ran\n",
    "data[\"TimeInterval\"] = data[\"TimeInterval\"].map(lambda x: [float(i) for i in x[1:-1].split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974d160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: One-Hot Encoding (Temporarily commented out to reduce memory consumption)\n",
    "# Either we use one-hot encoding or text embedding to represent the log features/text\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# unique_features = data[\"Features\"].map(lambda x: [i[1:] for i in x]).explode().unique().astype(np.int32)\n",
    "# unique_features.sort()\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output=False)\n",
    "# encoded_features = encoder.fit(unique_features.reshape(-1, 1))\n",
    "\n",
    "# data[\"Features_Encoded\"] = data[\"Features\"].map(lambda x: encoder.transform([[int(i[1:])] for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1204d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/toanquach/.local/share/virtualenvs/anomaly_detection_project-zdiuRa5q/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Text embedding using Sentence-BERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "template_data = pd.read_csv(\"data/preprocessed/HDFS.log_templates.csv\")\n",
    "\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "embeddings = model.encode(template_data['EventTemplate'].tolist())\n",
    "template_embedding_dict = {template_id: template_embedding for template_id, template_embedding in zip(template_data[\"EventId\"].tolist(), embeddings)}\n",
    "data[\"Features_Embedded\"] = data[\"Features\"].map(lambda x: [template_embedding_dict[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1e3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data to reduce memory usage\n",
    "data = data[[\"Features_Embedded\", \"TimeInterval\", \"Label\"]]\n",
    "del model\n",
    "del embeddings\n",
    "del template_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca09622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum length of sequence is chosen as 50 based on the distribution of sequence lengths\n",
    "# Sequences beyond this length are rare and has drippled effect on buiding even sequences\n",
    "# (i.e., padding/truncating) for training. Most short or medium sequences from 1 -> 40 in\n",
    "# length are padded up to 200s if this maximum length is not chosen.\n",
    "\n",
    "MAX_LEN = 50 # maximum sequence length\n",
    "EMBED_DIM = 384  # for 'all-MiniLM-L6-v2'\n",
    "\n",
    "# pad with zeros on the left to create even sequences for training\n",
    "def left_pad_feature(seq, pad_len=MAX_LEN, embed_dim=EMBED_DIM):\n",
    "    seq = np.stack(seq)  # shape: (L, 384)\n",
    "    L = seq.shape[0]\n",
    "    if L >= pad_len:\n",
    "        return seq[-pad_len:]  # truncate if too long\n",
    "    pad = np.zeros((pad_len - L, embed_dim), dtype=seq.dtype)\n",
    "    return np.vstack([pad, seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce1710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Features_Embedded_Padded\"] = data[\"Features_Embedded\"].map(left_pad_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba850756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"Features_Embedded_Padded\", \"TimeInterval\", \"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3496b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Features_Embedded_Padded\"] = data[\"Features_Embedded_Padded\"].map(lambda x: torch.from_numpy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf2e783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_labels = label_encoder.fit_transform(data[\"Label\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b89e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde78643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X = torch.stack(data[\"Features_Embedded_Padded\"].tolist())  # shape: (N, seq_len, 384)\n",
    "y = torch.from_numpy(encoded_labels)       # shape: (N, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c8e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de9988ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (80/20)\n",
    "N = len(X)\n",
    "train_size = int(0.8 * N)\n",
    "test_size = N - train_size\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f82f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=384, hidden_dim=128, num_layers=1, num_classes=None):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)  # hn: (num_layers, batch, hidden_dim)\n",
    "        out = self.fc(hn[-1])      # use last layer's hidden state\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7be9e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.shape[1]\n",
    "model = LSTMClassifier(input_dim=384, hidden_dim=128, num_layers=1, num_classes=num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss() if num_classes > 1 else nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05c8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.0029\n",
      "Test accuracy: 99.76%\n"
     ]
    }
   ],
   "source": [
    "# Training loop (1 epoch for demonstration)\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} loss: {loss.item():.4f}\")\n",
    "\n",
    "# Example: Evaluate on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        logits = model(xb)\n",
    "        preds = (logits > 0).float() if num_classes > 1 else logits.argmax(dim=1)\n",
    "        if num_classes > 1:\n",
    "            correct += (preds == yb).all(dim=1).sum().item()\n",
    "        else:\n",
    "            correct += (preds == yb.argmax(dim=1)).sum().item()\n",
    "        total += xb.size(0)\n",
    "print(f\"Test accuracy: {correct/total:.2%}\")\n",
    "    \n",
    "# Result after 1 output:\n",
    "# Epoch 1 loss: 0.0070\n",
    "# Test accuracy: 99.81%\n",
    "# NOTE: Most likely overfitting due to dataset highly skew toward success cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2c0bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fail     0.9860    0.9652    0.9755      3419\n",
      "     Success     0.9982    0.9993    0.9988     66936\n",
      "\n",
      "    accuracy                         0.9976     70355\n",
      "   macro avg     0.9921    0.9822    0.9871     70355\n",
      "weighted avg     0.9976    0.9976    0.9976     70355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        logits = model(xb)\n",
    "        \n",
    "        if num_classes > 1:\n",
    "            # Multi-class/One-hot: use argmax to get class index (0, 1, etc.)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            targets = torch.argmax(yb, dim=1)\n",
    "        else:\n",
    "            # Binary (single output neuron): threshold at 0\n",
    "            preds = (logits > 0).float().view(-1)\n",
    "            targets = yb.view(-1)\n",
    "            \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Get readable class names from the label encoder\n",
    "class_names = [str(c) for c in label_encoder.categories_[0]]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b87da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fee142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection_project-zdiuRa5q",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
